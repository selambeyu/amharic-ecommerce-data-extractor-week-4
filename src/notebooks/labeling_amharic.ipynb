{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93182470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# SETUP AND IMPORTS\n",
    "# ------------------------\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"../../data/telegram_data.csv\")\n",
    "messages = df[\"text\"].dropna().tolist()[:50]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4e1b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_amharic(text):\n",
    "    # Tokenize Amharic and numbers, fallback to whitespace for other tokens\n",
    "    tokens = re.findall(r'[\\u1200-\\u137F]+|\\d+|[^\\s\\u1200-\\u137F]+', str(text))\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b38876c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually label entities in the messages\n",
    "# Entity labels: B-Product, I-Product, B-LOC, I-LOC\n",
    "entity_labels = [\"B-Product\", \"I-Product\", \"B-LOC\", \"I-LOC\", \"B-PRICE\", \"I-PRICE\", \"O\"]\n",
    "labeled_sentences = []\n",
    "\n",
    "for idx, msg in enumerate(messages):\n",
    "    print(f\"\\nMessage {idx+1}: {msg}\")\n",
    "    tokens = tokenize_amharic(msg)\n",
    "    labels = []\n",
    "    for token in tokens:\n",
    "        print(f\"Token: {token}\")\n",
    "        label = input(f\"Label for '{token}' ({'/'.join(entity_labels)}): \")\n",
    "        if label not in entity_labels:\n",
    "            label = \"O\"\n",
    "        labels.append((token, label))\n",
    "    labeled_sentences.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d542f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save labeled data to a file \n",
    "with open(\"../../data/labeled_amharic.conll\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for sentence in labeled_sentences:\n",
    "        for token, label in sentence:\n",
    "            f.write(f\"{token} {label}\\n\")\n",
    "        f.write(\"\\n\")  # Sentence separator\n",
    "print(\"Saved labeled data to ../../data/labeled_amharic.conll\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
